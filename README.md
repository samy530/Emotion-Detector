# ğŸ­ DÃ©tection des Ã‰motions en Temps RÃ©el avec Python & OpenCV  

## ğŸ“Œ Description
Ce projet est une application de **dÃ©tection des Ã©motions faciales en temps rÃ©el** utilisant la **webcam**, **OpenCV**, et un modÃ¨le prÃ©-entraÃ®nÃ© en Deep Learning (`Emotion_Detection.h5`).  
L'application identifie automatiquement plusieurs Ã©motions parmi :  
ğŸ˜  Angry | ğŸ˜€ Happy | ğŸ˜ Neutral | ğŸ˜¢ Sad | ğŸ˜² Surprise  

Les visages sont encadrÃ©s avec des **couleurs diffÃ©rentes selon lâ€™Ã©motion dÃ©tectÃ©e**.  

## âš™ï¸ FonctionnalitÃ©s
âœ”ï¸ DÃ©tection faciale avec **Haar Cascade**  
âœ”ï¸ PrÃ©diction des Ã©motions avec un modÃ¨le entraÃ®nÃ© (`Emotion_Detection.h5`)  
âœ”ï¸ Support **multi-personnes** dans la mÃªme image  
âœ”ï¸ Couleurs diffÃ©rentes pour chaque Ã©motion (ex: rouge = Angry, vert = Happy, jaune = Surprise, etc.)  
âœ”ï¸ ExÃ©cution en **temps rÃ©el via webcam**  

---

## ğŸ“‚ Structure du projet
emotion-detector/
â”‚â”€â”€ haarcascade_frontalface_default.xml # Classifieur de visages
â”‚â”€â”€ Emotion_Detection.h5 # ModÃ¨le entraÃ®nÃ©
â”‚â”€â”€ test.py # Script principal
â”‚â”€â”€ train.py (optionnel) # Script dâ€™entraÃ®nement (si tu veux re-trainer)
â”‚â”€â”€ requirements.txt # DÃ©pendances Python
---
## ğŸš€ Installation & Utilisation

1ï¸âƒ£ Cloner le dÃ©pÃ´t
git clone https://github.com/ton-nom-utilisateur/emotion-detector.git
cd emotion-detector

2ï¸âƒ£ CrÃ©er un environnement virtuel (optionnel mais recommandÃ©)
python -m venv venv
# Activer l'environnement
# Sur Windows :
venv\Scripts\activate
# Sur Linux/Mac :
source venv/bin/activate

3ï¸âƒ£ Installer les dÃ©pendances
pip install -r requirements.txt

4ï¸âƒ£ Lancer lâ€™application
python test.py

5ï¸âƒ£ Quitter
Appuie sur Q pour fermer la fenÃªtre.

## ğŸ“¦ requirements.txt
CrÃ©e un fichier requirements.txt avec le contenu suivant :
opencv-python
tensorflow
numpy

## ğŸ“˜ Explications techniques
DÃ©tection des visages : faite avec haarcascade_frontalface_default.xml (classifieur OpenCV).
PrÃ©traitement : les visages sont redimensionnÃ©s en 48x48 et normalisÃ©s avant passage au modÃ¨le.
PrÃ©diction : le modÃ¨le (Emotion_Detection.h5) prÃ©dit lâ€™Ã©motion la plus probable.
Affichage : le visage est entourÃ© dâ€™un rectangle colorÃ© selon lâ€™Ã©motion, avec le label affichÃ© au-dessus.

## ğŸ”® AmÃ©liorations possibles
Ajouter une interface graphique (Tkinter ou PyQt).
Enregistrer les rÃ©sultats (vidÃ©o avec annotations).
HÃ©berger le modÃ¨le sur une appli web (Streamlit / Flask).
AmÃ©liorer le dataset avec un nouvel entraÃ®nement.
